{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more advanced introduction to scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will draw couple of boxplot during the tutorial. We need the plot to show in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides state-of-the-art machine learning algorithms. \n",
    "These algorithms, however, cannot be directly used on raw data. Raw data needs to be preprocessed beforehand. Thus, besides machine learning algorithms, `scikit-learn` provides a set of preprocessing methods. Furthermore, `scikit-learn` provides connectors for pipelining these estimators (i.e., transformer, regressor, classifier, clusterer, etc.). In this tutorial, we will present the set of `scikit-learn` functionalities allowing for pipelining estimators, evaluating those pipelines, tuning those pipelines using hyper-parameters optimization, and creating complex preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic use-case: train and test a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first example, we will train and test a classifier on a dataset. We will use this example to recall the API of `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `digits` dataset which is a dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` contains the intensities of the 64 image pixels. For each sample in `X`, we get the ground-truth `y` indicating the digit written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAA/5JREFUeJzt3cFRomkUhtGPqU6AFDAETAVC0BA0BHMhBAlBUjAECYFJwFlMld5unz5nyYLXAp76q9zcze12W0DHP7/7DwC+lqghRtQQI2qIETXE/PqON91sNsl/qR8Oh9G9l5eXsa3z+Ty29fz8PLZ1vV7HtqbdbrfNZ697UkOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHmW87uVE2ewVlrrd1uN7a13W7Htj4+Psa2jsfj2NZaa51Op9G9z3hSQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIebHn93Z7/djW5NncNZa6+7ubmzr/f19bOv19XVsa/L3sZazO8A3EDXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpifvwtre12O7Z1uVzGttaavW81afpz/Nt4UkOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHG2Z3/4Xw+j22VTX5n1+t1bOtP4UkNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGmB9/dmfyrMp+vx/bmjZ5CmfyczydTmNbfwpPaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcRsbrfb17/pZvP1b/ofdrvd1NR6e3sb21prrcfHx7Gtw+EwtjX5nd3f349tTbvdbpvPXvekhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIebH39Ka9PDwMLr39PQ0tnW5XMa2jsfj2FaZW1rwlxA1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xHzL2R3g9/GkhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmL+BXOCUu0hYKBYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap='gray');\n",
    "plt.axis('off')\n",
    "print('The digit in the image is {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we should check our model by training and testing it on distinct sets of data. `train_test_split` is a utility function to split the data into two independent sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have independent training and testing sets, we can learn a machine learning model using the `fit` method. We will use the `score` method to test this method, relying on the default accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API of `scikit-learn` is consistent across classifiers. Thus, we can easily replace the `LogisticRegression` classifier by a `RandomForestClassifier`. These changes are minimal and only related to the creation of the classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the RandomForestClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "TRAIN A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More advanced use-case: preprocess the data before training and testing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standardize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing might be required before learning a model. For instance, a user could be interested in creating hand-craft features or an algorithm might make some apriori on the data. In our case, the solver used by the `LogisticRegression` expects the data to be normalized. Thus, we need to standardize the data before training the model. To observe this necessary condition, we will check the number of iterations required to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression required 1493 iterations to be fitted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StandardScaler` is used to standardize the data. This scaler should be applied in the following way: learn (i.e., `fit` method) the statistics on a training set and standardized (i.e., `transform` method) the training and testing sets. Finally, we will train and test the model and the scaled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.98\n",
      "LogisticRegression required 89 iterations to be fitted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By scaling the data, the convergence of the model happened after only 89 iterations instead of 1493 iterations before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The wrong preprocessing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highlighted how to preprocess and adequately train a machine learning model. It is also interesting to spot what would be the wrong way of preprocessing data. There are two potential mistakes which are easy to make but easy to spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pattern is to standardize the data before spliting the full set into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.98\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_prescaled, X_test_prescaled, y_train_prescaled, y_test_prescaled = train_test_split(\n",
    "    X_scaled, y, stratify=y, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train_prescaled)\n",
    "accuracy = clf.score(X_test_prescaled, y_test_prescaled)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pattern is to standardize the training and testing sets independently. It comes back to call the `fit` methods on both training and testing sets. Thus, the training and testing sets are standardized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.98\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_prescaled = scaler.fit_transform(X_train)\n",
    "X_test_prescaled = scaler.fit_transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train)\n",
    "accuracy = clf.score(X_test_prescaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Keep it simple, stupid: use the pipeline connector from `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two previous patterns are an issue with data leaking. However, this is difficult to prevent such a mistake when one has to do the preprocessing by hand. Thus, `scikit-learn` introduced the `Pipeline` object. It sequentially connects several transformers and a classifier (or a regressor). We can create a pipeline as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                       ('clf', LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check all the parameters of the pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('clf',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "             n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "           n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'clf__C': 1.0,\n",
       " 'clf__class_weight': None,\n",
       " 'clf__dual': False,\n",
       " 'clf__fit_intercept': True,\n",
       " 'clf__intercept_scaling': 1,\n",
       " 'clf__max_iter': 100,\n",
       " 'clf__multi_class': 'auto',\n",
       " 'clf__n_jobs': None,\n",
       " 'clf__penalty': 'l2',\n",
       " 'clf__random_state': 42,\n",
       " 'clf__solver': 'lbfgs',\n",
       " 'clf__tol': 0.0001,\n",
       " 'clf__verbose': 0,\n",
       " 'clf__warm_start': False}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this pipeline contains the parameters of both the scaler and the classifier. Sometimes, it can be tedious to give a name to each estimator in the pipeline. `make_pipeline` will give a name automatically to each estimator which is the lower case of the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "             n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "           n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will have an identical API. We use `fit` to train the classifier and `score` to check the accuracy. However, calling `fit` will call the method `fit_transform` of all transformers in the pipeline. Calling `score` (or `predict` and `predict_proba`) will call internally `transform` of all transformers in the pipeline. It corresponds to the normalization procedure in Sect. 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.98\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "TRAIN A PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. When more is better than less: cross-validation instead of single split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data is necessary to evaluate the statistical model performance. However, it reduces the number of samples which can be used to learn the model. Therefore, one should use a cross-validation set whenever possible. Having multiple splits will give information about the model stability as well. `scikit-learn` provides three functions: `cross_val_score`, `cross_val_predict`, and `cross_validate`. The two former functions are a specific case of the latter one. Thus, we will focus on the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
    "                                        max_iter=1000, random_state=42))\n",
    "scores = cross_validate(pipe, X, y, scoring='balanced_accuracy', cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cross-validate functions, we can quickly check the training and testing scores and make fast plot using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093431</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.914322</td>\n",
       "      <td>0.998586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082534</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.881978</td>\n",
       "      <td>0.998586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.943810</td>\n",
       "      <td>0.998586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085219</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.963413</td>\n",
       "      <td>0.999306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076427</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.896172</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.093431    0.001052    0.914322     0.998586\n",
       "1  0.082534    0.001131    0.881978     0.998586\n",
       "2  0.080700    0.001014    0.943810     0.998586\n",
       "3  0.085219    0.001127    0.963413     0.999306\n",
       "4  0.076427    0.001101    0.896172     1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d444d3160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "CROSS-VALIDATE THE PREVIOUS PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper-parameters optimization: fine-tune the inside of pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you would like to find the parameters of a component of the pipeline which lead to the best accuracy. We already saw that we could check the parameters of a pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "             n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=1000, multi_class='auto',\n",
       "           n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 1000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner parameters can be optimized by an exhaustive search. `GridSearchCV` provides such utility and do it by cross-validation. Let's give an example in which we would like to optimize the `C` and `penalty` parameters of the `LogisticRegression` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto',\n",
    "                                        random_state=42))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "accuracy = grid.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the grid-search which found the best possible parameters on the training set (using cross-validation). Once those parameters are set, we check the model on the testing set. It is possible to introspect the grid to check the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1.0, 'logisticregression__penalty': 'l1'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily make a nested cross-validation, adding a grid-search within a cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.374753</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.922422</td>\n",
       "      <td>0.985330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.021774</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.895942</td>\n",
       "      <td>0.992970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.733252</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.943810</td>\n",
       "      <td>0.992319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.158918</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.957857</td>\n",
       "      <td>0.993699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.539431</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.890373</td>\n",
       "      <td>0.997221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  30.374753    0.002017    0.922422     0.985330\n",
       "1  32.021774    0.001667    0.895942     0.992970\n",
       "2  31.733252    0.002685    0.943810     0.992319\n",
       "3  32.158918    0.001403    0.957857     0.993699\n",
       "4  13.539431    0.003237    0.890373     0.997221"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "FINE TUNE THE PREVIOUS GRID-SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary: my scikit-learn pipeline in less than 10 lines of code (skipping the import statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d4440b320>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=10))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Heterogeneous data: when you work with data other than numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we used `scikit-learn` to train model using numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is a NumPy array of `float` values only. However, datasets can contains mixed types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = pd.read_csv(os.path.join('data', 'titanic_openml.csv'), na_values='?')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `titanic` dataset contains both categorical, text, and numeric. We will use this dataset to predict the survival rate on Titanic. Let's split the data into training and testing sets and use the `survived` column as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['survived']\n",
    "X = data.drop(columns='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could try a `LogisticRegression` classifier and see how good it is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremie/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'S'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f37cef5afafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1284\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/miniconda/envs/pyparis_sklearn/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'S'"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsy, most of the classifiers are designed to work with numerical data. Therefore, we need to convert the categorical data into numeric. The simplest way is to one-hot encode each category. Let's give an example for the `sex` and `embarked` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = make_pipeline(SimpleImputer(strategy='constant', fill_value='NA'), OneHotEncoder())\n",
    "X_encoded = ohe.fit_transform(X_train[['sex', 'embarked']])\n",
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it is possible to encode the categorical features. However, we also want to standardize the numerical column. Thus, we need to split the original data into 2 subgroups and apply a different preprocessing: (i) one-hot encoding for the categorical data and (ii) standard scaling for the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_cat = ['sex', 'embarked']\n",
    "col_num = ['age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "X_train_cat = X_train[col_cat]\n",
    "X_train_num = X_train[col_num]\n",
    "X_test_cat = X_test[col_cat]\n",
    "X_test_num = X_test[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_cat = make_pipeline(SimpleImputer(strategy='constant', fill_value='NA'), OneHotEncoder())\n",
    "X_train_cat_enc = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "scaler_num = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler_num.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should apply these transformations on the training and testing sets as we did in Sect. 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "X_train_scaled = sparse.hstack((X_train_cat_enc,\n",
    "                                sparse.csr_matrix(X_train_num_scaled)))\n",
    "X_test_scaled = sparse.hstack((X_test_cat_enc,\n",
    "                               sparse.csr_matrix(X_test_num_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transformation is done, we can combine the informations which are all numerical now. Finally, we use our `LogisticRegression` classifier as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.80\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern that we have here is exactly the one of Sect. 2.1. Therefore, we would like to use a pipeline for such purpose. However, we would also like to have different processing on different columns of our matrix. The `ColumnTransformer` is the transformer to use in this case. It is used to automatically apply different pipeline on different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant', fill_value='NA'),\n",
    "                         OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "preprocessor = ColumnTransformer([('trans_cat', pipe_cat, col_cat),\n",
    "                                  ('trans_num', pipe_num, col_num)])\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, it can also be used in another pipeline. Thus, we will be able to use all `scikit-learn` utilities as `cross_validate` or `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "            transformer_weights=None,\n",
       "            transformers=[('trans_cat', Pipeline(memory=None,\n",
       "        steps=[('simpleimputer', SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "          strategy='constant', verbose=0)), ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, han...r', StandardScaler(copy=True, with_mean=True, with_std=True))]), ['age', 'sibsp', 'parch', 'fare'])])),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "             intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "             n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "             tol=0.0001, verbose=0, warm_start=False))],\n",
       " 'columntransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "          transformer_weights=None,\n",
       "          transformers=[('trans_cat', Pipeline(memory=None,\n",
       "      steps=[('simpleimputer', SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "        strategy='constant', verbose=0)), ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "        dtype=<class 'numpy.float64'>, han...r', StandardScaler(copy=True, with_mean=True, with_std=True))]), ['age', 'sibsp', 'parch', 'fare'])]),\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "           n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('trans_cat', Pipeline(memory=None,\n",
       "        steps=[('simpleimputer', SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "          strategy='constant', verbose=0)), ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "          n_values=None, sparse=True))]), ['sex', 'embarked']),\n",
       "  ('trans_num', Pipeline(memory=None,\n",
       "        steps=[('simpleimputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]), ['age',\n",
       "    'sibsp',\n",
       "    'parch',\n",
       "    'fare'])],\n",
       " 'columntransformer__trans_cat': Pipeline(memory=None,\n",
       "      steps=[('simpleimputer', SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "        strategy='constant', verbose=0)), ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "        dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "        n_values=None, sparse=True))]),\n",
       " 'columntransformer__trans_num': Pipeline(memory=None,\n",
       "      steps=[('simpleimputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "        verbose=0)), ('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
       " 'columntransformer__trans_cat__memory': None,\n",
       " 'columntransformer__trans_cat__steps': [('simpleimputer',\n",
       "   SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "          strategy='constant', verbose=0)),\n",
       "  ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "          n_values=None, sparse=True))],\n",
       " 'columntransformer__trans_cat__simpleimputer': SimpleImputer(copy=True, fill_value='NA', missing_values=nan,\n",
       "        strategy='constant', verbose=0),\n",
       " 'columntransformer__trans_cat__onehotencoder': OneHotEncoder(categorical_features=None, categories=None,\n",
       "        dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "        n_values=None, sparse=True),\n",
       " 'columntransformer__trans_cat__simpleimputer__copy': True,\n",
       " 'columntransformer__trans_cat__simpleimputer__fill_value': 'NA',\n",
       " 'columntransformer__trans_cat__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__trans_cat__simpleimputer__strategy': 'constant',\n",
       " 'columntransformer__trans_cat__simpleimputer__verbose': 0,\n",
       " 'columntransformer__trans_cat__onehotencoder__categorical_features': None,\n",
       " 'columntransformer__trans_cat__onehotencoder__categories': None,\n",
       " 'columntransformer__trans_cat__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__trans_cat__onehotencoder__handle_unknown': 'ignore',\n",
       " 'columntransformer__trans_cat__onehotencoder__n_values': None,\n",
       " 'columntransformer__trans_cat__onehotencoder__sparse': True,\n",
       " 'columntransformer__trans_num__memory': None,\n",
       " 'columntransformer__trans_num__steps': [('simpleimputer',\n",
       "   SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'columntransformer__trans_num__simpleimputer': SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "        verbose=0),\n",
       " 'columntransformer__trans_num__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'columntransformer__trans_num__simpleimputer__copy': True,\n",
       " 'columntransformer__trans_num__simpleimputer__fill_value': None,\n",
       " 'columntransformer__trans_num__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__trans_num__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__trans_num__simpleimputer__verbose': 0,\n",
       " 'columntransformer__trans_num__standardscaler__copy': True,\n",
       " 'columntransformer__trans_num__standardscaler__with_mean': True,\n",
       " 'columntransformer__trans_num__standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'warn',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5d6620f208>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant', fill_value='NA'),\n",
    "                         OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "preprocessor = ColumnTransformer([('trans_cat', pipe_cat, col_cat),\n",
    "                                  ('trans_num', pipe_num, col_num)])\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "param_grid = {'columntransformer__trans_num__simpleimputer__strategy': ['mean', 'median'],\n",
    "              'logisticregression__C': [0.1, 1.0, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "MAKE YOU OWN COLUMNTRANSFORMER WITHIN A GRIDSEARCH AND CROSS-VALIDATION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
